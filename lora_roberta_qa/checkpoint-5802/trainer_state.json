{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 5802,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01723543605653223,
      "grad_norm": 5.390938758850098,
      "learning_rate": 4.9712742732391135e-05,
      "loss": 2.36,
      "step": 100
    },
    {
      "epoch": 0.03447087211306446,
      "grad_norm": 3.920808792114258,
      "learning_rate": 4.942548546478226e-05,
      "loss": 1.0026,
      "step": 200
    },
    {
      "epoch": 0.05170630816959669,
      "grad_norm": 8.19172477722168,
      "learning_rate": 4.913822819717339e-05,
      "loss": 0.7221,
      "step": 300
    },
    {
      "epoch": 0.06894174422612892,
      "grad_norm": 5.402547359466553,
      "learning_rate": 4.885097092956452e-05,
      "loss": 0.6531,
      "step": 400
    },
    {
      "epoch": 0.08617718028266115,
      "grad_norm": 2.4560861587524414,
      "learning_rate": 4.856371366195565e-05,
      "loss": 0.607,
      "step": 500
    },
    {
      "epoch": 0.10341261633919338,
      "grad_norm": 3.848334550857544,
      "learning_rate": 4.8276456394346784e-05,
      "loss": 0.6995,
      "step": 600
    },
    {
      "epoch": 0.12064805239572561,
      "grad_norm": 1.9669337272644043,
      "learning_rate": 4.798919912673791e-05,
      "loss": 0.6679,
      "step": 700
    },
    {
      "epoch": 0.13788348845225784,
      "grad_norm": 3.4233832359313965,
      "learning_rate": 4.770194185912904e-05,
      "loss": 0.5706,
      "step": 800
    },
    {
      "epoch": 0.15511892450879008,
      "grad_norm": 5.5549635887146,
      "learning_rate": 4.741468459152017e-05,
      "loss": 0.6029,
      "step": 900
    },
    {
      "epoch": 0.1723543605653223,
      "grad_norm": 9.962745666503906,
      "learning_rate": 4.71274273239113e-05,
      "loss": 0.6566,
      "step": 1000
    },
    {
      "epoch": 0.18958979662185454,
      "grad_norm": 2.63793683052063,
      "learning_rate": 4.6840170056302426e-05,
      "loss": 0.6453,
      "step": 1100
    },
    {
      "epoch": 0.20682523267838676,
      "grad_norm": 10.882122993469238,
      "learning_rate": 4.655291278869355e-05,
      "loss": 0.5846,
      "step": 1200
    },
    {
      "epoch": 0.224060668734919,
      "grad_norm": 10.712789535522461,
      "learning_rate": 4.6265655521084684e-05,
      "loss": 0.6308,
      "step": 1300
    },
    {
      "epoch": 0.24129610479145122,
      "grad_norm": 15.037240028381348,
      "learning_rate": 4.597839825347581e-05,
      "loss": 0.643,
      "step": 1400
    },
    {
      "epoch": 0.25853154084798347,
      "grad_norm": 1.7117284536361694,
      "learning_rate": 4.569114098586694e-05,
      "loss": 0.6407,
      "step": 1500
    },
    {
      "epoch": 0.2757669769045157,
      "grad_norm": 1.3685063123703003,
      "learning_rate": 4.5403883718258075e-05,
      "loss": 0.557,
      "step": 1600
    },
    {
      "epoch": 0.2930024129610479,
      "grad_norm": 6.014193058013916,
      "learning_rate": 4.51166264506492e-05,
      "loss": 0.6257,
      "step": 1700
    },
    {
      "epoch": 0.31023784901758017,
      "grad_norm": 2.981790781021118,
      "learning_rate": 4.4829369183040333e-05,
      "loss": 0.546,
      "step": 1800
    },
    {
      "epoch": 0.3274732850741124,
      "grad_norm": 3.3044638633728027,
      "learning_rate": 4.454211191543146e-05,
      "loss": 0.5633,
      "step": 1900
    },
    {
      "epoch": 0.3447087211306446,
      "grad_norm": 1.4876312017440796,
      "learning_rate": 4.425485464782259e-05,
      "loss": 0.5507,
      "step": 2000
    },
    {
      "epoch": 0.3619441571871768,
      "grad_norm": 7.851777076721191,
      "learning_rate": 4.3967597380213724e-05,
      "loss": 0.5997,
      "step": 2100
    },
    {
      "epoch": 0.3791795932437091,
      "grad_norm": 4.015218257904053,
      "learning_rate": 4.368034011260485e-05,
      "loss": 0.5068,
      "step": 2200
    },
    {
      "epoch": 0.3964150293002413,
      "grad_norm": 3.9788191318511963,
      "learning_rate": 4.339308284499598e-05,
      "loss": 0.5476,
      "step": 2300
    },
    {
      "epoch": 0.4136504653567735,
      "grad_norm": 1.7610902786254883,
      "learning_rate": 4.310582557738711e-05,
      "loss": 0.5635,
      "step": 2400
    },
    {
      "epoch": 0.43088590141330574,
      "grad_norm": 1.1808114051818848,
      "learning_rate": 4.281856830977824e-05,
      "loss": 0.5669,
      "step": 2500
    },
    {
      "epoch": 0.448121337469838,
      "grad_norm": 4.063233375549316,
      "learning_rate": 4.2531311042169366e-05,
      "loss": 0.5789,
      "step": 2600
    },
    {
      "epoch": 0.4653567735263702,
      "grad_norm": 7.237565517425537,
      "learning_rate": 4.22440537745605e-05,
      "loss": 0.5052,
      "step": 2700
    },
    {
      "epoch": 0.48259220958290244,
      "grad_norm": 7.537424564361572,
      "learning_rate": 4.195679650695163e-05,
      "loss": 0.5909,
      "step": 2800
    },
    {
      "epoch": 0.49982764563943466,
      "grad_norm": 3.195362091064453,
      "learning_rate": 4.166953923934276e-05,
      "loss": 0.5782,
      "step": 2900
    },
    {
      "epoch": 0.5170630816959669,
      "grad_norm": 1.1472214460372925,
      "learning_rate": 4.138228197173389e-05,
      "loss": 0.5117,
      "step": 3000
    },
    {
      "epoch": 0.5342985177524991,
      "grad_norm": 1.5303635597229004,
      "learning_rate": 4.1095024704125016e-05,
      "loss": 0.5569,
      "step": 3100
    },
    {
      "epoch": 0.5515339538090314,
      "grad_norm": 1.9153953790664673,
      "learning_rate": 4.080776743651615e-05,
      "loss": 0.532,
      "step": 3200
    },
    {
      "epoch": 0.5687693898655636,
      "grad_norm": 3.296602725982666,
      "learning_rate": 4.052051016890728e-05,
      "loss": 0.4672,
      "step": 3300
    },
    {
      "epoch": 0.5860048259220958,
      "grad_norm": 5.8541259765625,
      "learning_rate": 4.0233252901298406e-05,
      "loss": 0.538,
      "step": 3400
    },
    {
      "epoch": 0.603240261978628,
      "grad_norm": 1.1353687047958374,
      "learning_rate": 3.994599563368954e-05,
      "loss": 0.6357,
      "step": 3500
    },
    {
      "epoch": 0.6204756980351603,
      "grad_norm": 5.916767120361328,
      "learning_rate": 3.965873836608066e-05,
      "loss": 0.5647,
      "step": 3600
    },
    {
      "epoch": 0.6377111340916926,
      "grad_norm": 1.6726462841033936,
      "learning_rate": 3.937148109847179e-05,
      "loss": 0.5455,
      "step": 3700
    },
    {
      "epoch": 0.6549465701482248,
      "grad_norm": 13.134613037109375,
      "learning_rate": 3.908422383086292e-05,
      "loss": 0.5654,
      "step": 3800
    },
    {
      "epoch": 0.672182006204757,
      "grad_norm": 4.1718010902404785,
      "learning_rate": 3.879696656325405e-05,
      "loss": 0.4764,
      "step": 3900
    },
    {
      "epoch": 0.6894174422612892,
      "grad_norm": 1.2366399765014648,
      "learning_rate": 3.850970929564518e-05,
      "loss": 0.5339,
      "step": 4000
    },
    {
      "epoch": 0.7066528783178214,
      "grad_norm": 3.8493504524230957,
      "learning_rate": 3.822245202803631e-05,
      "loss": 0.5571,
      "step": 4100
    },
    {
      "epoch": 0.7238883143743536,
      "grad_norm": 3.70676326751709,
      "learning_rate": 3.793519476042744e-05,
      "loss": 0.5734,
      "step": 4200
    },
    {
      "epoch": 0.7411237504308859,
      "grad_norm": 4.168738842010498,
      "learning_rate": 3.764793749281857e-05,
      "loss": 0.5271,
      "step": 4300
    },
    {
      "epoch": 0.7583591864874182,
      "grad_norm": 7.584662437438965,
      "learning_rate": 3.73606802252097e-05,
      "loss": 0.4537,
      "step": 4400
    },
    {
      "epoch": 0.7755946225439504,
      "grad_norm": 10.988677978515625,
      "learning_rate": 3.707342295760083e-05,
      "loss": 0.5578,
      "step": 4500
    },
    {
      "epoch": 0.7928300586004826,
      "grad_norm": 3.667327404022217,
      "learning_rate": 3.6786165689991956e-05,
      "loss": 0.5454,
      "step": 4600
    },
    {
      "epoch": 0.8100654946570148,
      "grad_norm": 28.22623062133789,
      "learning_rate": 3.649890842238309e-05,
      "loss": 0.548,
      "step": 4700
    },
    {
      "epoch": 0.827300930713547,
      "grad_norm": 5.801459312438965,
      "learning_rate": 3.621165115477422e-05,
      "loss": 0.5162,
      "step": 4800
    },
    {
      "epoch": 0.8445363667700793,
      "grad_norm": 6.580316543579102,
      "learning_rate": 3.5924393887165347e-05,
      "loss": 0.5309,
      "step": 4900
    },
    {
      "epoch": 0.8617718028266115,
      "grad_norm": 6.564026355743408,
      "learning_rate": 3.563713661955648e-05,
      "loss": 0.4692,
      "step": 5000
    },
    {
      "epoch": 0.8790072388831437,
      "grad_norm": 1.8069803714752197,
      "learning_rate": 3.5349879351947605e-05,
      "loss": 0.569,
      "step": 5100
    },
    {
      "epoch": 0.896242674939676,
      "grad_norm": 5.052165985107422,
      "learning_rate": 3.506262208433874e-05,
      "loss": 0.4198,
      "step": 5200
    },
    {
      "epoch": 0.9134781109962082,
      "grad_norm": 4.616978645324707,
      "learning_rate": 3.477536481672986e-05,
      "loss": 0.5442,
      "step": 5300
    },
    {
      "epoch": 0.9307135470527405,
      "grad_norm": 4.312023162841797,
      "learning_rate": 3.4488107549120996e-05,
      "loss": 0.5647,
      "step": 5400
    },
    {
      "epoch": 0.9479489831092727,
      "grad_norm": 5.375576496124268,
      "learning_rate": 3.420085028151213e-05,
      "loss": 0.5505,
      "step": 5500
    },
    {
      "epoch": 0.9651844191658049,
      "grad_norm": 6.46795129776001,
      "learning_rate": 3.3913593013903254e-05,
      "loss": 0.5124,
      "step": 5600
    },
    {
      "epoch": 0.9824198552223371,
      "grad_norm": 2.0932629108428955,
      "learning_rate": 3.3626335746294386e-05,
      "loss": 0.4475,
      "step": 5700
    },
    {
      "epoch": 0.9996552912788693,
      "grad_norm": 7.26353120803833,
      "learning_rate": 3.333907847868551e-05,
      "loss": 0.6054,
      "step": 5800
    },
    {
      "epoch": 1.0,
      "eval_runtime": 67.3658,
      "eval_samples_per_second": 163.867,
      "eval_steps_per_second": 20.485,
      "step": 5802
    }
  ],
  "logging_steps": 100,
  "max_steps": 17406,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9127408007347200.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
