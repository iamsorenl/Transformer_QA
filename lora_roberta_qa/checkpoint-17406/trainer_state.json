{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 17406,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01723543605653223,
      "grad_norm": 5.390938758850098,
      "learning_rate": 4.9712742732391135e-05,
      "loss": 2.36,
      "step": 100
    },
    {
      "epoch": 0.03447087211306446,
      "grad_norm": 3.920808792114258,
      "learning_rate": 4.942548546478226e-05,
      "loss": 1.0026,
      "step": 200
    },
    {
      "epoch": 0.05170630816959669,
      "grad_norm": 8.19172477722168,
      "learning_rate": 4.913822819717339e-05,
      "loss": 0.7221,
      "step": 300
    },
    {
      "epoch": 0.06894174422612892,
      "grad_norm": 5.402547359466553,
      "learning_rate": 4.885097092956452e-05,
      "loss": 0.6531,
      "step": 400
    },
    {
      "epoch": 0.08617718028266115,
      "grad_norm": 2.4560861587524414,
      "learning_rate": 4.856371366195565e-05,
      "loss": 0.607,
      "step": 500
    },
    {
      "epoch": 0.10341261633919338,
      "grad_norm": 3.848334550857544,
      "learning_rate": 4.8276456394346784e-05,
      "loss": 0.6995,
      "step": 600
    },
    {
      "epoch": 0.12064805239572561,
      "grad_norm": 1.9669337272644043,
      "learning_rate": 4.798919912673791e-05,
      "loss": 0.6679,
      "step": 700
    },
    {
      "epoch": 0.13788348845225784,
      "grad_norm": 3.4233832359313965,
      "learning_rate": 4.770194185912904e-05,
      "loss": 0.5706,
      "step": 800
    },
    {
      "epoch": 0.15511892450879008,
      "grad_norm": 5.5549635887146,
      "learning_rate": 4.741468459152017e-05,
      "loss": 0.6029,
      "step": 900
    },
    {
      "epoch": 0.1723543605653223,
      "grad_norm": 9.962745666503906,
      "learning_rate": 4.71274273239113e-05,
      "loss": 0.6566,
      "step": 1000
    },
    {
      "epoch": 0.18958979662185454,
      "grad_norm": 2.63793683052063,
      "learning_rate": 4.6840170056302426e-05,
      "loss": 0.6453,
      "step": 1100
    },
    {
      "epoch": 0.20682523267838676,
      "grad_norm": 10.882122993469238,
      "learning_rate": 4.655291278869355e-05,
      "loss": 0.5846,
      "step": 1200
    },
    {
      "epoch": 0.224060668734919,
      "grad_norm": 10.712789535522461,
      "learning_rate": 4.6265655521084684e-05,
      "loss": 0.6308,
      "step": 1300
    },
    {
      "epoch": 0.24129610479145122,
      "grad_norm": 15.037240028381348,
      "learning_rate": 4.597839825347581e-05,
      "loss": 0.643,
      "step": 1400
    },
    {
      "epoch": 0.25853154084798347,
      "grad_norm": 1.7117284536361694,
      "learning_rate": 4.569114098586694e-05,
      "loss": 0.6407,
      "step": 1500
    },
    {
      "epoch": 0.2757669769045157,
      "grad_norm": 1.3685063123703003,
      "learning_rate": 4.5403883718258075e-05,
      "loss": 0.557,
      "step": 1600
    },
    {
      "epoch": 0.2930024129610479,
      "grad_norm": 6.014193058013916,
      "learning_rate": 4.51166264506492e-05,
      "loss": 0.6257,
      "step": 1700
    },
    {
      "epoch": 0.31023784901758017,
      "grad_norm": 2.981790781021118,
      "learning_rate": 4.4829369183040333e-05,
      "loss": 0.546,
      "step": 1800
    },
    {
      "epoch": 0.3274732850741124,
      "grad_norm": 3.3044638633728027,
      "learning_rate": 4.454211191543146e-05,
      "loss": 0.5633,
      "step": 1900
    },
    {
      "epoch": 0.3447087211306446,
      "grad_norm": 1.4876312017440796,
      "learning_rate": 4.425485464782259e-05,
      "loss": 0.5507,
      "step": 2000
    },
    {
      "epoch": 0.3619441571871768,
      "grad_norm": 7.851777076721191,
      "learning_rate": 4.3967597380213724e-05,
      "loss": 0.5997,
      "step": 2100
    },
    {
      "epoch": 0.3791795932437091,
      "grad_norm": 4.015218257904053,
      "learning_rate": 4.368034011260485e-05,
      "loss": 0.5068,
      "step": 2200
    },
    {
      "epoch": 0.3964150293002413,
      "grad_norm": 3.9788191318511963,
      "learning_rate": 4.339308284499598e-05,
      "loss": 0.5476,
      "step": 2300
    },
    {
      "epoch": 0.4136504653567735,
      "grad_norm": 1.7610902786254883,
      "learning_rate": 4.310582557738711e-05,
      "loss": 0.5635,
      "step": 2400
    },
    {
      "epoch": 0.43088590141330574,
      "grad_norm": 1.1808114051818848,
      "learning_rate": 4.281856830977824e-05,
      "loss": 0.5669,
      "step": 2500
    },
    {
      "epoch": 0.448121337469838,
      "grad_norm": 4.063233375549316,
      "learning_rate": 4.2531311042169366e-05,
      "loss": 0.5789,
      "step": 2600
    },
    {
      "epoch": 0.4653567735263702,
      "grad_norm": 7.237565517425537,
      "learning_rate": 4.22440537745605e-05,
      "loss": 0.5052,
      "step": 2700
    },
    {
      "epoch": 0.48259220958290244,
      "grad_norm": 7.537424564361572,
      "learning_rate": 4.195679650695163e-05,
      "loss": 0.5909,
      "step": 2800
    },
    {
      "epoch": 0.49982764563943466,
      "grad_norm": 3.195362091064453,
      "learning_rate": 4.166953923934276e-05,
      "loss": 0.5782,
      "step": 2900
    },
    {
      "epoch": 0.5170630816959669,
      "grad_norm": 1.1472214460372925,
      "learning_rate": 4.138228197173389e-05,
      "loss": 0.5117,
      "step": 3000
    },
    {
      "epoch": 0.5342985177524991,
      "grad_norm": 1.5303635597229004,
      "learning_rate": 4.1095024704125016e-05,
      "loss": 0.5569,
      "step": 3100
    },
    {
      "epoch": 0.5515339538090314,
      "grad_norm": 1.9153953790664673,
      "learning_rate": 4.080776743651615e-05,
      "loss": 0.532,
      "step": 3200
    },
    {
      "epoch": 0.5687693898655636,
      "grad_norm": 3.296602725982666,
      "learning_rate": 4.052051016890728e-05,
      "loss": 0.4672,
      "step": 3300
    },
    {
      "epoch": 0.5860048259220958,
      "grad_norm": 5.8541259765625,
      "learning_rate": 4.0233252901298406e-05,
      "loss": 0.538,
      "step": 3400
    },
    {
      "epoch": 0.603240261978628,
      "grad_norm": 1.1353687047958374,
      "learning_rate": 3.994599563368954e-05,
      "loss": 0.6357,
      "step": 3500
    },
    {
      "epoch": 0.6204756980351603,
      "grad_norm": 5.916767120361328,
      "learning_rate": 3.965873836608066e-05,
      "loss": 0.5647,
      "step": 3600
    },
    {
      "epoch": 0.6377111340916926,
      "grad_norm": 1.6726462841033936,
      "learning_rate": 3.937148109847179e-05,
      "loss": 0.5455,
      "step": 3700
    },
    {
      "epoch": 0.6549465701482248,
      "grad_norm": 13.134613037109375,
      "learning_rate": 3.908422383086292e-05,
      "loss": 0.5654,
      "step": 3800
    },
    {
      "epoch": 0.672182006204757,
      "grad_norm": 4.1718010902404785,
      "learning_rate": 3.879696656325405e-05,
      "loss": 0.4764,
      "step": 3900
    },
    {
      "epoch": 0.6894174422612892,
      "grad_norm": 1.2366399765014648,
      "learning_rate": 3.850970929564518e-05,
      "loss": 0.5339,
      "step": 4000
    },
    {
      "epoch": 0.7066528783178214,
      "grad_norm": 3.8493504524230957,
      "learning_rate": 3.822245202803631e-05,
      "loss": 0.5571,
      "step": 4100
    },
    {
      "epoch": 0.7238883143743536,
      "grad_norm": 3.70676326751709,
      "learning_rate": 3.793519476042744e-05,
      "loss": 0.5734,
      "step": 4200
    },
    {
      "epoch": 0.7411237504308859,
      "grad_norm": 4.168738842010498,
      "learning_rate": 3.764793749281857e-05,
      "loss": 0.5271,
      "step": 4300
    },
    {
      "epoch": 0.7583591864874182,
      "grad_norm": 7.584662437438965,
      "learning_rate": 3.73606802252097e-05,
      "loss": 0.4537,
      "step": 4400
    },
    {
      "epoch": 0.7755946225439504,
      "grad_norm": 10.988677978515625,
      "learning_rate": 3.707342295760083e-05,
      "loss": 0.5578,
      "step": 4500
    },
    {
      "epoch": 0.7928300586004826,
      "grad_norm": 3.667327404022217,
      "learning_rate": 3.6786165689991956e-05,
      "loss": 0.5454,
      "step": 4600
    },
    {
      "epoch": 0.8100654946570148,
      "grad_norm": 28.22623062133789,
      "learning_rate": 3.649890842238309e-05,
      "loss": 0.548,
      "step": 4700
    },
    {
      "epoch": 0.827300930713547,
      "grad_norm": 5.801459312438965,
      "learning_rate": 3.621165115477422e-05,
      "loss": 0.5162,
      "step": 4800
    },
    {
      "epoch": 0.8445363667700793,
      "grad_norm": 6.580316543579102,
      "learning_rate": 3.5924393887165347e-05,
      "loss": 0.5309,
      "step": 4900
    },
    {
      "epoch": 0.8617718028266115,
      "grad_norm": 6.564026355743408,
      "learning_rate": 3.563713661955648e-05,
      "loss": 0.4692,
      "step": 5000
    },
    {
      "epoch": 0.8790072388831437,
      "grad_norm": 1.8069803714752197,
      "learning_rate": 3.5349879351947605e-05,
      "loss": 0.569,
      "step": 5100
    },
    {
      "epoch": 0.896242674939676,
      "grad_norm": 5.052165985107422,
      "learning_rate": 3.506262208433874e-05,
      "loss": 0.4198,
      "step": 5200
    },
    {
      "epoch": 0.9134781109962082,
      "grad_norm": 4.616978645324707,
      "learning_rate": 3.477536481672986e-05,
      "loss": 0.5442,
      "step": 5300
    },
    {
      "epoch": 0.9307135470527405,
      "grad_norm": 4.312023162841797,
      "learning_rate": 3.4488107549120996e-05,
      "loss": 0.5647,
      "step": 5400
    },
    {
      "epoch": 0.9479489831092727,
      "grad_norm": 5.375576496124268,
      "learning_rate": 3.420085028151213e-05,
      "loss": 0.5505,
      "step": 5500
    },
    {
      "epoch": 0.9651844191658049,
      "grad_norm": 6.46795129776001,
      "learning_rate": 3.3913593013903254e-05,
      "loss": 0.5124,
      "step": 5600
    },
    {
      "epoch": 0.9824198552223371,
      "grad_norm": 2.0932629108428955,
      "learning_rate": 3.3626335746294386e-05,
      "loss": 0.4475,
      "step": 5700
    },
    {
      "epoch": 0.9996552912788693,
      "grad_norm": 7.26353120803833,
      "learning_rate": 3.333907847868551e-05,
      "loss": 0.6054,
      "step": 5800
    },
    {
      "epoch": 1.0,
      "eval_runtime": 67.3658,
      "eval_samples_per_second": 163.867,
      "eval_steps_per_second": 20.485,
      "step": 5802
    },
    {
      "epoch": 1.0168907273354015,
      "grad_norm": 2.6878035068511963,
      "learning_rate": 3.3051821211076645e-05,
      "loss": 0.4793,
      "step": 5900
    },
    {
      "epoch": 1.0341261633919339,
      "grad_norm": 1.3886713981628418,
      "learning_rate": 3.276456394346777e-05,
      "loss": 0.5438,
      "step": 6000
    },
    {
      "epoch": 1.051361599448466,
      "grad_norm": 2.124845504760742,
      "learning_rate": 3.2477306675858896e-05,
      "loss": 0.5102,
      "step": 6100
    },
    {
      "epoch": 1.0685970355049983,
      "grad_norm": 3.1923182010650635,
      "learning_rate": 3.219004940825003e-05,
      "loss": 0.4326,
      "step": 6200
    },
    {
      "epoch": 1.0858324715615306,
      "grad_norm": 5.0833024978637695,
      "learning_rate": 3.190279214064116e-05,
      "loss": 0.5326,
      "step": 6300
    },
    {
      "epoch": 1.1030679076180627,
      "grad_norm": 8.524409294128418,
      "learning_rate": 3.161553487303229e-05,
      "loss": 0.4675,
      "step": 6400
    },
    {
      "epoch": 1.120303343674595,
      "grad_norm": 3.6577091217041016,
      "learning_rate": 3.132827760542342e-05,
      "loss": 0.5764,
      "step": 6500
    },
    {
      "epoch": 1.1375387797311272,
      "grad_norm": 2.2764456272125244,
      "learning_rate": 3.1041020337814545e-05,
      "loss": 0.4682,
      "step": 6600
    },
    {
      "epoch": 1.1547742157876595,
      "grad_norm": 2.627833843231201,
      "learning_rate": 3.075376307020568e-05,
      "loss": 0.5608,
      "step": 6700
    },
    {
      "epoch": 1.1720096518441916,
      "grad_norm": 4.205041885375977,
      "learning_rate": 3.0466505802596807e-05,
      "loss": 0.4959,
      "step": 6800
    },
    {
      "epoch": 1.189245087900724,
      "grad_norm": 2.6669604778289795,
      "learning_rate": 3.0179248534987936e-05,
      "loss": 0.4314,
      "step": 6900
    },
    {
      "epoch": 1.206480523957256,
      "grad_norm": 6.657658100128174,
      "learning_rate": 2.9891991267379065e-05,
      "loss": 0.5244,
      "step": 7000
    },
    {
      "epoch": 1.2237159600137884,
      "grad_norm": 6.816940784454346,
      "learning_rate": 2.9604733999770194e-05,
      "loss": 0.5419,
      "step": 7100
    },
    {
      "epoch": 1.2409513960703205,
      "grad_norm": 4.674582004547119,
      "learning_rate": 2.9317476732161327e-05,
      "loss": 0.3921,
      "step": 7200
    },
    {
      "epoch": 1.2581868321268528,
      "grad_norm": 10.72015380859375,
      "learning_rate": 2.9030219464552456e-05,
      "loss": 0.4979,
      "step": 7300
    },
    {
      "epoch": 1.275422268183385,
      "grad_norm": 2.486285924911499,
      "learning_rate": 2.8742962196943585e-05,
      "loss": 0.453,
      "step": 7400
    },
    {
      "epoch": 1.2926577042399172,
      "grad_norm": 3.3148458003997803,
      "learning_rate": 2.8455704929334714e-05,
      "loss": 0.4294,
      "step": 7500
    },
    {
      "epoch": 1.3098931402964495,
      "grad_norm": 5.234818458557129,
      "learning_rate": 2.8168447661725843e-05,
      "loss": 0.466,
      "step": 7600
    },
    {
      "epoch": 1.3271285763529816,
      "grad_norm": 5.346196174621582,
      "learning_rate": 2.7881190394116972e-05,
      "loss": 0.4645,
      "step": 7700
    },
    {
      "epoch": 1.344364012409514,
      "grad_norm": 2.0738141536712646,
      "learning_rate": 2.7593933126508105e-05,
      "loss": 0.4601,
      "step": 7800
    },
    {
      "epoch": 1.361599448466046,
      "grad_norm": 3.7320339679718018,
      "learning_rate": 2.7306675858899234e-05,
      "loss": 0.4725,
      "step": 7900
    },
    {
      "epoch": 1.3788348845225784,
      "grad_norm": 4.568080902099609,
      "learning_rate": 2.7019418591290363e-05,
      "loss": 0.5138,
      "step": 8000
    },
    {
      "epoch": 1.3960703205791107,
      "grad_norm": 2.8717167377471924,
      "learning_rate": 2.6732161323681492e-05,
      "loss": 0.4357,
      "step": 8100
    },
    {
      "epoch": 1.4133057566356428,
      "grad_norm": 7.458010673522949,
      "learning_rate": 2.644490405607262e-05,
      "loss": 0.49,
      "step": 8200
    },
    {
      "epoch": 1.4305411926921752,
      "grad_norm": 2.48111629486084,
      "learning_rate": 2.6157646788463747e-05,
      "loss": 0.4384,
      "step": 8300
    },
    {
      "epoch": 1.4477766287487073,
      "grad_norm": 12.345311164855957,
      "learning_rate": 2.5870389520854876e-05,
      "loss": 0.461,
      "step": 8400
    },
    {
      "epoch": 1.4650120648052396,
      "grad_norm": 3.7435548305511475,
      "learning_rate": 2.5583132253246005e-05,
      "loss": 0.4592,
      "step": 8500
    },
    {
      "epoch": 1.4822475008617717,
      "grad_norm": 2.762120008468628,
      "learning_rate": 2.5295874985637135e-05,
      "loss": 0.4999,
      "step": 8600
    },
    {
      "epoch": 1.499482936918304,
      "grad_norm": 5.946252822875977,
      "learning_rate": 2.5008617718028267e-05,
      "loss": 0.4464,
      "step": 8700
    },
    {
      "epoch": 1.5167183729748364,
      "grad_norm": 7.674015998840332,
      "learning_rate": 2.47213604504194e-05,
      "loss": 0.4329,
      "step": 8800
    },
    {
      "epoch": 1.5339538090313685,
      "grad_norm": 1.813786506652832,
      "learning_rate": 2.4434103182810525e-05,
      "loss": 0.4861,
      "step": 8900
    },
    {
      "epoch": 1.5511892450879006,
      "grad_norm": 9.15449047088623,
      "learning_rate": 2.4146845915201654e-05,
      "loss": 0.3795,
      "step": 9000
    },
    {
      "epoch": 1.5684246811444331,
      "grad_norm": 8.509553909301758,
      "learning_rate": 2.3859588647592784e-05,
      "loss": 0.4448,
      "step": 9100
    },
    {
      "epoch": 1.5856601172009652,
      "grad_norm": 3.868647575378418,
      "learning_rate": 2.3572331379983913e-05,
      "loss": 0.4318,
      "step": 9200
    },
    {
      "epoch": 1.6028955532574973,
      "grad_norm": 6.587282657623291,
      "learning_rate": 2.3285074112375045e-05,
      "loss": 0.5214,
      "step": 9300
    },
    {
      "epoch": 1.6201309893140297,
      "grad_norm": 5.173702716827393,
      "learning_rate": 2.2997816844766174e-05,
      "loss": 0.4759,
      "step": 9400
    },
    {
      "epoch": 1.637366425370562,
      "grad_norm": 13.053510665893555,
      "learning_rate": 2.2710559577157303e-05,
      "loss": 0.5091,
      "step": 9500
    },
    {
      "epoch": 1.654601861427094,
      "grad_norm": 5.840139865875244,
      "learning_rate": 2.2423302309548433e-05,
      "loss": 0.4156,
      "step": 9600
    },
    {
      "epoch": 1.6718372974836262,
      "grad_norm": 4.414468765258789,
      "learning_rate": 2.213604504193956e-05,
      "loss": 0.5086,
      "step": 9700
    },
    {
      "epoch": 1.6890727335401585,
      "grad_norm": 3.7575368881225586,
      "learning_rate": 2.184878777433069e-05,
      "loss": 0.3667,
      "step": 9800
    },
    {
      "epoch": 1.7063081695966908,
      "grad_norm": 3.0392420291900635,
      "learning_rate": 2.1561530506721823e-05,
      "loss": 0.5083,
      "step": 9900
    },
    {
      "epoch": 1.723543605653223,
      "grad_norm": 3.7745773792266846,
      "learning_rate": 2.1274273239112952e-05,
      "loss": 0.4539,
      "step": 10000
    },
    {
      "epoch": 1.7407790417097553,
      "grad_norm": 10.218427658081055,
      "learning_rate": 2.0987015971504078e-05,
      "loss": 0.5049,
      "step": 10100
    },
    {
      "epoch": 1.7580144777662876,
      "grad_norm": 12.605648040771484,
      "learning_rate": 2.0699758703895207e-05,
      "loss": 0.4622,
      "step": 10200
    },
    {
      "epoch": 1.7752499138228197,
      "grad_norm": 11.4906587600708,
      "learning_rate": 2.041250143628634e-05,
      "loss": 0.4564,
      "step": 10300
    },
    {
      "epoch": 1.7924853498793518,
      "grad_norm": 4.355892181396484,
      "learning_rate": 2.012524416867747e-05,
      "loss": 0.4333,
      "step": 10400
    },
    {
      "epoch": 1.8097207859358841,
      "grad_norm": 1.866815447807312,
      "learning_rate": 1.9837986901068598e-05,
      "loss": 0.4371,
      "step": 10500
    },
    {
      "epoch": 1.8269562219924165,
      "grad_norm": 8.375828742980957,
      "learning_rate": 1.9550729633459727e-05,
      "loss": 0.4624,
      "step": 10600
    },
    {
      "epoch": 1.8441916580489486,
      "grad_norm": 13.243513107299805,
      "learning_rate": 1.9263472365850856e-05,
      "loss": 0.519,
      "step": 10700
    },
    {
      "epoch": 1.861427094105481,
      "grad_norm": 4.11094856262207,
      "learning_rate": 1.8976215098241985e-05,
      "loss": 0.5211,
      "step": 10800
    },
    {
      "epoch": 1.8786625301620132,
      "grad_norm": 10.121448516845703,
      "learning_rate": 1.8688957830633118e-05,
      "loss": 0.4797,
      "step": 10900
    },
    {
      "epoch": 1.8958979662185453,
      "grad_norm": 3.4346554279327393,
      "learning_rate": 1.8401700563024247e-05,
      "loss": 0.4483,
      "step": 11000
    },
    {
      "epoch": 1.9131334022750774,
      "grad_norm": 10.770408630371094,
      "learning_rate": 1.8114443295415376e-05,
      "loss": 0.4215,
      "step": 11100
    },
    {
      "epoch": 1.9303688383316098,
      "grad_norm": 3.350414514541626,
      "learning_rate": 1.7827186027806505e-05,
      "loss": 0.4468,
      "step": 11200
    },
    {
      "epoch": 1.947604274388142,
      "grad_norm": 9.62446403503418,
      "learning_rate": 1.753992876019763e-05,
      "loss": 0.4819,
      "step": 11300
    },
    {
      "epoch": 1.9648397104446742,
      "grad_norm": 4.90012788772583,
      "learning_rate": 1.7252671492588764e-05,
      "loss": 0.4006,
      "step": 11400
    },
    {
      "epoch": 1.9820751465012065,
      "grad_norm": 7.497345924377441,
      "learning_rate": 1.6965414224979893e-05,
      "loss": 0.4857,
      "step": 11500
    },
    {
      "epoch": 1.9993105825577389,
      "grad_norm": 9.810142517089844,
      "learning_rate": 1.6678156957371022e-05,
      "loss": 0.4061,
      "step": 11600
    },
    {
      "epoch": 2.0,
      "eval_runtime": 67.0155,
      "eval_samples_per_second": 164.723,
      "eval_steps_per_second": 20.592,
      "step": 11604
    },
    {
      "epoch": 2.016546018614271,
      "grad_norm": 3.4760630130767822,
      "learning_rate": 1.639089968976215e-05,
      "loss": 0.4365,
      "step": 11700
    },
    {
      "epoch": 2.033781454670803,
      "grad_norm": 7.268405914306641,
      "learning_rate": 1.610364242215328e-05,
      "loss": 0.4907,
      "step": 11800
    },
    {
      "epoch": 2.0510168907273356,
      "grad_norm": 5.587965965270996,
      "learning_rate": 1.581638515454441e-05,
      "loss": 0.4116,
      "step": 11900
    },
    {
      "epoch": 2.0682523267838677,
      "grad_norm": 4.164417266845703,
      "learning_rate": 1.5529127886935542e-05,
      "loss": 0.4394,
      "step": 12000
    },
    {
      "epoch": 2.0854877628404,
      "grad_norm": 6.8298749923706055,
      "learning_rate": 1.5241870619326671e-05,
      "loss": 0.4286,
      "step": 12100
    },
    {
      "epoch": 2.102723198896932,
      "grad_norm": 10.656481742858887,
      "learning_rate": 1.49546133517178e-05,
      "loss": 0.483,
      "step": 12200
    },
    {
      "epoch": 2.1199586349534645,
      "grad_norm": 4.1264328956604,
      "learning_rate": 1.466735608410893e-05,
      "loss": 0.4279,
      "step": 12300
    },
    {
      "epoch": 2.1371940710099966,
      "grad_norm": 4.152277946472168,
      "learning_rate": 1.438009881650006e-05,
      "loss": 0.3901,
      "step": 12400
    },
    {
      "epoch": 2.1544295070665287,
      "grad_norm": 10.60198974609375,
      "learning_rate": 1.4092841548891186e-05,
      "loss": 0.4919,
      "step": 12500
    },
    {
      "epoch": 2.1716649431230612,
      "grad_norm": 5.426580905914307,
      "learning_rate": 1.3805584281282317e-05,
      "loss": 0.3792,
      "step": 12600
    },
    {
      "epoch": 2.1889003791795933,
      "grad_norm": 4.585768699645996,
      "learning_rate": 1.3518327013673446e-05,
      "loss": 0.4499,
      "step": 12700
    },
    {
      "epoch": 2.2061358152361255,
      "grad_norm": 4.963472843170166,
      "learning_rate": 1.3231069746064575e-05,
      "loss": 0.4371,
      "step": 12800
    },
    {
      "epoch": 2.2233712512926576,
      "grad_norm": 7.792491436004639,
      "learning_rate": 1.2943812478455706e-05,
      "loss": 0.496,
      "step": 12900
    },
    {
      "epoch": 2.24060668734919,
      "grad_norm": 13.74423599243164,
      "learning_rate": 1.2656555210846835e-05,
      "loss": 0.4932,
      "step": 13000
    },
    {
      "epoch": 2.257842123405722,
      "grad_norm": 2.7806453704833984,
      "learning_rate": 1.2369297943237964e-05,
      "loss": 0.3897,
      "step": 13100
    },
    {
      "epoch": 2.2750775594622543,
      "grad_norm": 5.228321552276611,
      "learning_rate": 1.2082040675629095e-05,
      "loss": 0.4063,
      "step": 13200
    },
    {
      "epoch": 2.2923129955187864,
      "grad_norm": 11.121186256408691,
      "learning_rate": 1.1794783408020224e-05,
      "loss": 0.4508,
      "step": 13300
    },
    {
      "epoch": 2.309548431575319,
      "grad_norm": 3.574237108230591,
      "learning_rate": 1.1507526140411353e-05,
      "loss": 0.4068,
      "step": 13400
    },
    {
      "epoch": 2.326783867631851,
      "grad_norm": 21.0087890625,
      "learning_rate": 1.1220268872802482e-05,
      "loss": 0.4282,
      "step": 13500
    },
    {
      "epoch": 2.344019303688383,
      "grad_norm": 7.760806083679199,
      "learning_rate": 1.0933011605193611e-05,
      "loss": 0.449,
      "step": 13600
    },
    {
      "epoch": 2.3612547397449157,
      "grad_norm": 8.910813331604004,
      "learning_rate": 1.0645754337584742e-05,
      "loss": 0.4134,
      "step": 13700
    },
    {
      "epoch": 2.378490175801448,
      "grad_norm": 6.968632221221924,
      "learning_rate": 1.0358497069975871e-05,
      "loss": 0.3586,
      "step": 13800
    },
    {
      "epoch": 2.39572561185798,
      "grad_norm": 3.430562973022461,
      "learning_rate": 1.0071239802367e-05,
      "loss": 0.496,
      "step": 13900
    },
    {
      "epoch": 2.412961047914512,
      "grad_norm": 2.693686008453369,
      "learning_rate": 9.78398253475813e-06,
      "loss": 0.4097,
      "step": 14000
    },
    {
      "epoch": 2.4301964839710446,
      "grad_norm": 2.97299861907959,
      "learning_rate": 9.496725267149259e-06,
      "loss": 0.4779,
      "step": 14100
    },
    {
      "epoch": 2.4474319200275767,
      "grad_norm": 9.022517204284668,
      "learning_rate": 9.20946799954039e-06,
      "loss": 0.4364,
      "step": 14200
    },
    {
      "epoch": 2.464667356084109,
      "grad_norm": 5.829038619995117,
      "learning_rate": 8.922210731931519e-06,
      "loss": 0.43,
      "step": 14300
    },
    {
      "epoch": 2.481902792140641,
      "grad_norm": 8.528176307678223,
      "learning_rate": 8.634953464322648e-06,
      "loss": 0.4138,
      "step": 14400
    },
    {
      "epoch": 2.4991382281971735,
      "grad_norm": 4.371429920196533,
      "learning_rate": 8.347696196713778e-06,
      "loss": 0.4359,
      "step": 14500
    },
    {
      "epoch": 2.5163736642537056,
      "grad_norm": 5.152275085449219,
      "learning_rate": 8.060438929104906e-06,
      "loss": 0.4247,
      "step": 14600
    },
    {
      "epoch": 2.5336091003102377,
      "grad_norm": 5.195781230926514,
      "learning_rate": 7.773181661496037e-06,
      "loss": 0.4351,
      "step": 14700
    },
    {
      "epoch": 2.55084453636677,
      "grad_norm": 3.0908362865448,
      "learning_rate": 7.485924393887166e-06,
      "loss": 0.4259,
      "step": 14800
    },
    {
      "epoch": 2.5680799724233023,
      "grad_norm": 4.380374431610107,
      "learning_rate": 7.198667126278295e-06,
      "loss": 0.4521,
      "step": 14900
    },
    {
      "epoch": 2.5853154084798344,
      "grad_norm": 5.992251873016357,
      "learning_rate": 6.911409858669425e-06,
      "loss": 0.3977,
      "step": 15000
    },
    {
      "epoch": 2.602550844536367,
      "grad_norm": 4.260750770568848,
      "learning_rate": 6.624152591060555e-06,
      "loss": 0.4275,
      "step": 15100
    },
    {
      "epoch": 2.619786280592899,
      "grad_norm": 8.927597999572754,
      "learning_rate": 6.336895323451683e-06,
      "loss": 0.4225,
      "step": 15200
    },
    {
      "epoch": 2.637021716649431,
      "grad_norm": 1.9542385339736938,
      "learning_rate": 6.049638055842813e-06,
      "loss": 0.3523,
      "step": 15300
    },
    {
      "epoch": 2.6542571527059633,
      "grad_norm": 6.243806838989258,
      "learning_rate": 5.762380788233942e-06,
      "loss": 0.4368,
      "step": 15400
    },
    {
      "epoch": 2.671492588762496,
      "grad_norm": 12.590709686279297,
      "learning_rate": 5.475123520625072e-06,
      "loss": 0.4629,
      "step": 15500
    },
    {
      "epoch": 2.688728024819028,
      "grad_norm": 7.076922416687012,
      "learning_rate": 5.187866253016201e-06,
      "loss": 0.3736,
      "step": 15600
    },
    {
      "epoch": 2.70596346087556,
      "grad_norm": 9.262251853942871,
      "learning_rate": 4.900608985407331e-06,
      "loss": 0.466,
      "step": 15700
    },
    {
      "epoch": 2.723198896932092,
      "grad_norm": 3.2621798515319824,
      "learning_rate": 4.6133517177984605e-06,
      "loss": 0.4214,
      "step": 15800
    },
    {
      "epoch": 2.7404343329886247,
      "grad_norm": 8.872743606567383,
      "learning_rate": 4.32609445018959e-06,
      "loss": 0.4323,
      "step": 15900
    },
    {
      "epoch": 2.757669769045157,
      "grad_norm": 9.990127563476562,
      "learning_rate": 4.03883718258072e-06,
      "loss": 0.4773,
      "step": 16000
    },
    {
      "epoch": 2.774905205101689,
      "grad_norm": 7.547574043273926,
      "learning_rate": 3.751579914971849e-06,
      "loss": 0.4041,
      "step": 16100
    },
    {
      "epoch": 2.7921406411582215,
      "grad_norm": 4.651103496551514,
      "learning_rate": 3.4643226473629783e-06,
      "loss": 0.4263,
      "step": 16200
    },
    {
      "epoch": 2.8093760772147536,
      "grad_norm": 6.436947822570801,
      "learning_rate": 3.177065379754108e-06,
      "loss": 0.4558,
      "step": 16300
    },
    {
      "epoch": 2.8266115132712857,
      "grad_norm": 10.119614601135254,
      "learning_rate": 2.8898081121452374e-06,
      "loss": 0.3806,
      "step": 16400
    },
    {
      "epoch": 2.8438469493278182,
      "grad_norm": 8.85802173614502,
      "learning_rate": 2.602550844536367e-06,
      "loss": 0.4089,
      "step": 16500
    },
    {
      "epoch": 2.8610823853843503,
      "grad_norm": 14.563682556152344,
      "learning_rate": 2.3152935769274965e-06,
      "loss": 0.3868,
      "step": 16600
    },
    {
      "epoch": 2.8783178214408824,
      "grad_norm": 5.155175685882568,
      "learning_rate": 2.0280363093186256e-06,
      "loss": 0.3825,
      "step": 16700
    },
    {
      "epoch": 2.8955532574974145,
      "grad_norm": 12.580708503723145,
      "learning_rate": 1.7407790417097554e-06,
      "loss": 0.4469,
      "step": 16800
    },
    {
      "epoch": 2.9127886935539467,
      "grad_norm": 7.6783766746521,
      "learning_rate": 1.4535217741008847e-06,
      "loss": 0.3891,
      "step": 16900
    },
    {
      "epoch": 2.930024129610479,
      "grad_norm": 12.778809547424316,
      "learning_rate": 1.1662645064920143e-06,
      "loss": 0.4119,
      "step": 17000
    },
    {
      "epoch": 2.9472595656670113,
      "grad_norm": 7.6725687980651855,
      "learning_rate": 8.790072388831437e-07,
      "loss": 0.392,
      "step": 17100
    },
    {
      "epoch": 2.9644950017235434,
      "grad_norm": 2.725050210952759,
      "learning_rate": 5.917499712742733e-07,
      "loss": 0.3962,
      "step": 17200
    },
    {
      "epoch": 2.981730437780076,
      "grad_norm": 17.62305450439453,
      "learning_rate": 3.044927036654027e-07,
      "loss": 0.4023,
      "step": 17300
    },
    {
      "epoch": 2.998965873836608,
      "grad_norm": 7.0078864097595215,
      "learning_rate": 1.723543605653223e-08,
      "loss": 0.4234,
      "step": 17400
    },
    {
      "epoch": 3.0,
      "eval_runtime": 67.7633,
      "eval_samples_per_second": 162.905,
      "eval_steps_per_second": 20.365,
      "step": 17406
    }
  ],
  "logging_steps": 100,
  "max_steps": 17406,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.73822240220416e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
