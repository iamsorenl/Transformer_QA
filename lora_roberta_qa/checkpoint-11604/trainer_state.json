{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 11604,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01723543605653223,
      "grad_norm": 7.6205620765686035,
      "learning_rate": 4.9712742732391135e-05,
      "loss": 0.253,
      "step": 100
    },
    {
      "epoch": 0.03447087211306446,
      "grad_norm": 0.2454054355621338,
      "learning_rate": 4.942548546478226e-05,
      "loss": 0.166,
      "step": 200
    },
    {
      "epoch": 0.05170630816959669,
      "grad_norm": 2.38935923576355,
      "learning_rate": 4.913822819717339e-05,
      "loss": 0.186,
      "step": 300
    },
    {
      "epoch": 0.06894174422612892,
      "grad_norm": 0.023900693282485008,
      "learning_rate": 4.885097092956452e-05,
      "loss": 0.1622,
      "step": 400
    },
    {
      "epoch": 0.08617718028266115,
      "grad_norm": 0.02737485244870186,
      "learning_rate": 4.856371366195565e-05,
      "loss": 0.1716,
      "step": 500
    },
    {
      "epoch": 0.10341261633919338,
      "grad_norm": 6.706140518188477,
      "learning_rate": 4.8276456394346784e-05,
      "loss": 0.3146,
      "step": 600
    },
    {
      "epoch": 0.12064805239572561,
      "grad_norm": 0.14641745388507843,
      "learning_rate": 4.798919912673791e-05,
      "loss": 0.2603,
      "step": 700
    },
    {
      "epoch": 0.13788348845225784,
      "grad_norm": 0.028273625299334526,
      "learning_rate": 4.770194185912904e-05,
      "loss": 0.1651,
      "step": 800
    },
    {
      "epoch": 0.15511892450879008,
      "grad_norm": 0.07351156324148178,
      "learning_rate": 4.741468459152017e-05,
      "loss": 0.2227,
      "step": 900
    },
    {
      "epoch": 0.1723543605653223,
      "grad_norm": 5.914494514465332,
      "learning_rate": 4.71274273239113e-05,
      "loss": 0.1981,
      "step": 1000
    },
    {
      "epoch": 0.18958979662185454,
      "grad_norm": 0.01177926640957594,
      "learning_rate": 4.6840170056302426e-05,
      "loss": 0.2374,
      "step": 1100
    },
    {
      "epoch": 0.20682523267838676,
      "grad_norm": 5.851393222808838,
      "learning_rate": 4.655291278869355e-05,
      "loss": 0.1903,
      "step": 1200
    },
    {
      "epoch": 0.224060668734919,
      "grad_norm": 5.301523685455322,
      "learning_rate": 4.6265655521084684e-05,
      "loss": 0.1949,
      "step": 1300
    },
    {
      "epoch": 0.24129610479145122,
      "grad_norm": 0.028925038874149323,
      "learning_rate": 4.597839825347581e-05,
      "loss": 0.2732,
      "step": 1400
    },
    {
      "epoch": 0.25853154084798347,
      "grad_norm": 0.020910825580358505,
      "learning_rate": 4.569114098586694e-05,
      "loss": 0.2526,
      "step": 1500
    },
    {
      "epoch": 0.2757669769045157,
      "grad_norm": 0.022322237491607666,
      "learning_rate": 4.5403883718258075e-05,
      "loss": 0.1897,
      "step": 1600
    },
    {
      "epoch": 0.2930024129610479,
      "grad_norm": 0.027316031977534294,
      "learning_rate": 4.51166264506492e-05,
      "loss": 0.2516,
      "step": 1700
    },
    {
      "epoch": 0.31023784901758017,
      "grad_norm": 0.030294911935925484,
      "learning_rate": 4.4829369183040333e-05,
      "loss": 0.2122,
      "step": 1800
    },
    {
      "epoch": 0.3274732850741124,
      "grad_norm": 0.013508678413927555,
      "learning_rate": 4.454211191543146e-05,
      "loss": 0.2129,
      "step": 1900
    },
    {
      "epoch": 0.3447087211306446,
      "grad_norm": 0.029151899740099907,
      "learning_rate": 4.425485464782259e-05,
      "loss": 0.1737,
      "step": 2000
    },
    {
      "epoch": 0.3619441571871768,
      "grad_norm": 3.6424694061279297,
      "learning_rate": 4.3967597380213724e-05,
      "loss": 0.2452,
      "step": 2100
    },
    {
      "epoch": 0.3791795932437091,
      "grad_norm": 4.591037750244141,
      "learning_rate": 4.368034011260485e-05,
      "loss": 0.1802,
      "step": 2200
    },
    {
      "epoch": 0.3964150293002413,
      "grad_norm": 1.675487756729126,
      "learning_rate": 4.339308284499598e-05,
      "loss": 0.2162,
      "step": 2300
    },
    {
      "epoch": 0.4136504653567735,
      "grad_norm": 0.0898471549153328,
      "learning_rate": 4.310582557738711e-05,
      "loss": 0.2701,
      "step": 2400
    },
    {
      "epoch": 0.43088590141330574,
      "grad_norm": 0.10593422502279282,
      "learning_rate": 4.281856830977824e-05,
      "loss": 0.2233,
      "step": 2500
    },
    {
      "epoch": 0.448121337469838,
      "grad_norm": 0.21227578818798065,
      "learning_rate": 4.2531311042169366e-05,
      "loss": 0.241,
      "step": 2600
    },
    {
      "epoch": 0.4653567735263702,
      "grad_norm": 4.538839340209961,
      "learning_rate": 4.22440537745605e-05,
      "loss": 0.1493,
      "step": 2700
    },
    {
      "epoch": 0.48259220958290244,
      "grad_norm": 9.06640338897705,
      "learning_rate": 4.195679650695163e-05,
      "loss": 0.2004,
      "step": 2800
    },
    {
      "epoch": 0.49982764563943466,
      "grad_norm": 2.798413038253784,
      "learning_rate": 4.166953923934276e-05,
      "loss": 0.2025,
      "step": 2900
    },
    {
      "epoch": 0.5170630816959669,
      "grad_norm": 0.3511175215244293,
      "learning_rate": 4.138228197173389e-05,
      "loss": 0.2047,
      "step": 3000
    },
    {
      "epoch": 0.5342985177524991,
      "grad_norm": 0.24776121973991394,
      "learning_rate": 4.1095024704125016e-05,
      "loss": 0.2065,
      "step": 3100
    },
    {
      "epoch": 0.5515339538090314,
      "grad_norm": 0.04146436229348183,
      "learning_rate": 4.080776743651615e-05,
      "loss": 0.2055,
      "step": 3200
    },
    {
      "epoch": 0.5687693898655636,
      "grad_norm": 1.1536880731582642,
      "learning_rate": 4.052051016890728e-05,
      "loss": 0.1397,
      "step": 3300
    },
    {
      "epoch": 0.5860048259220958,
      "grad_norm": 2.9715070724487305,
      "learning_rate": 4.0233252901298406e-05,
      "loss": 0.2137,
      "step": 3400
    },
    {
      "epoch": 0.603240261978628,
      "grad_norm": 0.17877766489982605,
      "learning_rate": 3.994599563368954e-05,
      "loss": 0.2767,
      "step": 3500
    },
    {
      "epoch": 0.6204756980351603,
      "grad_norm": 1.223763108253479,
      "learning_rate": 3.965873836608066e-05,
      "loss": 0.2219,
      "step": 3600
    },
    {
      "epoch": 0.6377111340916926,
      "grad_norm": 0.4664756655693054,
      "learning_rate": 3.937148109847179e-05,
      "loss": 0.2396,
      "step": 3700
    },
    {
      "epoch": 0.6549465701482248,
      "grad_norm": 1.913285255432129,
      "learning_rate": 3.908422383086292e-05,
      "loss": 0.2289,
      "step": 3800
    },
    {
      "epoch": 0.672182006204757,
      "grad_norm": 0.28364139795303345,
      "learning_rate": 3.879696656325405e-05,
      "loss": 0.1658,
      "step": 3900
    },
    {
      "epoch": 0.6894174422612892,
      "grad_norm": 0.02711339481174946,
      "learning_rate": 3.850970929564518e-05,
      "loss": 0.2126,
      "step": 4000
    },
    {
      "epoch": 0.7066528783178214,
      "grad_norm": 0.016586212441325188,
      "learning_rate": 3.822245202803631e-05,
      "loss": 0.2153,
      "step": 4100
    },
    {
      "epoch": 0.7238883143743536,
      "grad_norm": 0.13161170482635498,
      "learning_rate": 3.793519476042744e-05,
      "loss": 0.2007,
      "step": 4200
    },
    {
      "epoch": 0.7411237504308859,
      "grad_norm": 2.1095361709594727,
      "learning_rate": 3.764793749281857e-05,
      "loss": 0.178,
      "step": 4300
    },
    {
      "epoch": 0.7583591864874182,
      "grad_norm": 4.140219688415527,
      "learning_rate": 3.73606802252097e-05,
      "loss": 0.1162,
      "step": 4400
    },
    {
      "epoch": 0.7755946225439504,
      "grad_norm": 0.07762553542852402,
      "learning_rate": 3.707342295760083e-05,
      "loss": 0.2659,
      "step": 4500
    },
    {
      "epoch": 0.7928300586004826,
      "grad_norm": 1.1761360168457031,
      "learning_rate": 3.6786165689991956e-05,
      "loss": 0.2557,
      "step": 4600
    },
    {
      "epoch": 0.8100654946570148,
      "grad_norm": 1.7579511404037476,
      "learning_rate": 3.649890842238309e-05,
      "loss": 0.2284,
      "step": 4700
    },
    {
      "epoch": 0.827300930713547,
      "grad_norm": 3.655259132385254,
      "learning_rate": 3.621165115477422e-05,
      "loss": 0.2007,
      "step": 4800
    },
    {
      "epoch": 0.8445363667700793,
      "grad_norm": 0.19180461764335632,
      "learning_rate": 3.5924393887165347e-05,
      "loss": 0.2297,
      "step": 4900
    },
    {
      "epoch": 0.8617718028266115,
      "grad_norm": 0.6156086921691895,
      "learning_rate": 3.563713661955648e-05,
      "loss": 0.1258,
      "step": 5000
    },
    {
      "epoch": 0.8790072388831437,
      "grad_norm": 0.04665073752403259,
      "learning_rate": 3.5349879351947605e-05,
      "loss": 0.1899,
      "step": 5100
    },
    {
      "epoch": 0.896242674939676,
      "grad_norm": 0.18399430811405182,
      "learning_rate": 3.506262208433874e-05,
      "loss": 0.0996,
      "step": 5200
    },
    {
      "epoch": 0.9134781109962082,
      "grad_norm": 0.5933322310447693,
      "learning_rate": 3.477536481672986e-05,
      "loss": 0.2024,
      "step": 5300
    },
    {
      "epoch": 0.9307135470527405,
      "grad_norm": 0.4447498321533203,
      "learning_rate": 3.4488107549120996e-05,
      "loss": 0.2134,
      "step": 5400
    },
    {
      "epoch": 0.9479489831092727,
      "grad_norm": 0.039000511169433594,
      "learning_rate": 3.420085028151213e-05,
      "loss": 0.2112,
      "step": 5500
    },
    {
      "epoch": 0.9651844191658049,
      "grad_norm": 4.3056182861328125,
      "learning_rate": 3.3913593013903254e-05,
      "loss": 0.2074,
      "step": 5600
    },
    {
      "epoch": 0.9824198552223371,
      "grad_norm": 0.12523959577083588,
      "learning_rate": 3.3626335746294386e-05,
      "loss": 0.1303,
      "step": 5700
    },
    {
      "epoch": 0.9996552912788693,
      "grad_norm": 3.5532028675079346,
      "learning_rate": 3.333907847868551e-05,
      "loss": 0.3137,
      "step": 5800
    },
    {
      "epoch": 1.0,
      "eval_runtime": 25.9604,
      "eval_samples_per_second": 163.095,
      "eval_steps_per_second": 20.416,
      "step": 5802
    },
    {
      "epoch": 1.0168907273354015,
      "grad_norm": 0.12034100294113159,
      "learning_rate": 3.3051821211076645e-05,
      "loss": 0.1696,
      "step": 5900
    },
    {
      "epoch": 1.0341261633919339,
      "grad_norm": 0.024852024391293526,
      "learning_rate": 3.276456394346777e-05,
      "loss": 0.2049,
      "step": 6000
    },
    {
      "epoch": 1.051361599448466,
      "grad_norm": 0.0181125421077013,
      "learning_rate": 3.2477306675858896e-05,
      "loss": 0.21,
      "step": 6100
    },
    {
      "epoch": 1.0685970355049983,
      "grad_norm": 0.32577937841415405,
      "learning_rate": 3.219004940825003e-05,
      "loss": 0.1119,
      "step": 6200
    },
    {
      "epoch": 1.0858324715615306,
      "grad_norm": 1.2662855386734009,
      "learning_rate": 3.190279214064116e-05,
      "loss": 0.2246,
      "step": 6300
    },
    {
      "epoch": 1.1030679076180627,
      "grad_norm": 6.02161169052124,
      "learning_rate": 3.161553487303229e-05,
      "loss": 0.1674,
      "step": 6400
    },
    {
      "epoch": 1.120303343674595,
      "grad_norm": 0.019369186833500862,
      "learning_rate": 3.132827760542342e-05,
      "loss": 0.2722,
      "step": 6500
    },
    {
      "epoch": 1.1375387797311272,
      "grad_norm": 0.20274117588996887,
      "learning_rate": 3.1041020337814545e-05,
      "loss": 0.1694,
      "step": 6600
    },
    {
      "epoch": 1.1547742157876595,
      "grad_norm": 0.037011004984378815,
      "learning_rate": 3.075376307020568e-05,
      "loss": 0.2243,
      "step": 6700
    },
    {
      "epoch": 1.1720096518441916,
      "grad_norm": 0.031906645745038986,
      "learning_rate": 3.0466505802596807e-05,
      "loss": 0.1835,
      "step": 6800
    },
    {
      "epoch": 1.189245087900724,
      "grad_norm": 0.026606373488903046,
      "learning_rate": 3.0179248534987936e-05,
      "loss": 0.1607,
      "step": 6900
    },
    {
      "epoch": 1.206480523957256,
      "grad_norm": 0.29120340943336487,
      "learning_rate": 2.9891991267379065e-05,
      "loss": 0.1922,
      "step": 7000
    },
    {
      "epoch": 1.2237159600137884,
      "grad_norm": 0.18842852115631104,
      "learning_rate": 2.9604733999770194e-05,
      "loss": 0.2476,
      "step": 7100
    },
    {
      "epoch": 1.2409513960703205,
      "grad_norm": 0.011768966913223267,
      "learning_rate": 2.9317476732161327e-05,
      "loss": 0.1297,
      "step": 7200
    },
    {
      "epoch": 1.2581868321268528,
      "grad_norm": 0.052502311766147614,
      "learning_rate": 2.9030219464552456e-05,
      "loss": 0.2017,
      "step": 7300
    },
    {
      "epoch": 1.275422268183385,
      "grad_norm": 0.06335368007421494,
      "learning_rate": 2.8742962196943585e-05,
      "loss": 0.1678,
      "step": 7400
    },
    {
      "epoch": 1.2926577042399172,
      "grad_norm": 0.07488147169351578,
      "learning_rate": 2.8455704929334714e-05,
      "loss": 0.1562,
      "step": 7500
    },
    {
      "epoch": 1.3098931402964495,
      "grad_norm": 3.625930070877075,
      "learning_rate": 2.8168447661725843e-05,
      "loss": 0.2148,
      "step": 7600
    },
    {
      "epoch": 1.3271285763529816,
      "grad_norm": 0.7036265134811401,
      "learning_rate": 2.7881190394116972e-05,
      "loss": 0.2103,
      "step": 7700
    },
    {
      "epoch": 1.344364012409514,
      "grad_norm": 0.312094122171402,
      "learning_rate": 2.7593933126508105e-05,
      "loss": 0.1748,
      "step": 7800
    },
    {
      "epoch": 1.361599448466046,
      "grad_norm": 0.04076119884848595,
      "learning_rate": 2.7306675858899234e-05,
      "loss": 0.1493,
      "step": 7900
    },
    {
      "epoch": 1.3788348845225784,
      "grad_norm": 0.014140864834189415,
      "learning_rate": 2.7019418591290363e-05,
      "loss": 0.1799,
      "step": 8000
    },
    {
      "epoch": 1.3960703205791107,
      "grad_norm": 0.9954224824905396,
      "learning_rate": 2.6732161323681492e-05,
      "loss": 0.1543,
      "step": 8100
    },
    {
      "epoch": 1.4133057566356428,
      "grad_norm": 0.02131233550608158,
      "learning_rate": 2.644490405607262e-05,
      "loss": 0.2229,
      "step": 8200
    },
    {
      "epoch": 1.4305411926921752,
      "grad_norm": 0.03468018025159836,
      "learning_rate": 2.6157646788463747e-05,
      "loss": 0.1724,
      "step": 8300
    },
    {
      "epoch": 1.4477766287487073,
      "grad_norm": 2.9326093196868896,
      "learning_rate": 2.5870389520854876e-05,
      "loss": 0.1696,
      "step": 8400
    },
    {
      "epoch": 1.4650120648052396,
      "grad_norm": 0.0413161963224411,
      "learning_rate": 2.5583132253246005e-05,
      "loss": 0.1695,
      "step": 8500
    },
    {
      "epoch": 1.4822475008617717,
      "grad_norm": 2.313042640686035,
      "learning_rate": 2.5295874985637135e-05,
      "loss": 0.2166,
      "step": 8600
    },
    {
      "epoch": 1.499482936918304,
      "grad_norm": 0.26377856731414795,
      "learning_rate": 2.5008617718028267e-05,
      "loss": 0.1552,
      "step": 8700
    },
    {
      "epoch": 1.5167183729748364,
      "grad_norm": 0.5537375211715698,
      "learning_rate": 2.47213604504194e-05,
      "loss": 0.1575,
      "step": 8800
    },
    {
      "epoch": 1.5339538090313685,
      "grad_norm": 0.2631002366542816,
      "learning_rate": 2.4434103182810525e-05,
      "loss": 0.1833,
      "step": 8900
    },
    {
      "epoch": 1.5511892450879006,
      "grad_norm": 0.028338730335235596,
      "learning_rate": 2.4146845915201654e-05,
      "loss": 0.1105,
      "step": 9000
    },
    {
      "epoch": 1.5684246811444331,
      "grad_norm": 5.407066345214844,
      "learning_rate": 2.3859588647592784e-05,
      "loss": 0.1742,
      "step": 9100
    },
    {
      "epoch": 1.5856601172009652,
      "grad_norm": 0.19017067551612854,
      "learning_rate": 2.3572331379983913e-05,
      "loss": 0.1842,
      "step": 9200
    },
    {
      "epoch": 1.6028955532574973,
      "grad_norm": 1.0996342897415161,
      "learning_rate": 2.3285074112375045e-05,
      "loss": 0.2076,
      "step": 9300
    },
    {
      "epoch": 1.6201309893140297,
      "grad_norm": 0.19456763565540314,
      "learning_rate": 2.2997816844766174e-05,
      "loss": 0.1825,
      "step": 9400
    },
    {
      "epoch": 1.637366425370562,
      "grad_norm": 8.067358016967773,
      "learning_rate": 2.2710559577157303e-05,
      "loss": 0.246,
      "step": 9500
    },
    {
      "epoch": 1.654601861427094,
      "grad_norm": 0.17411650717258453,
      "learning_rate": 2.2423302309548433e-05,
      "loss": 0.1422,
      "step": 9600
    },
    {
      "epoch": 1.6718372974836262,
      "grad_norm": 1.1745502948760986,
      "learning_rate": 2.213604504193956e-05,
      "loss": 0.264,
      "step": 9700
    },
    {
      "epoch": 1.6890727335401585,
      "grad_norm": 0.14695610105991364,
      "learning_rate": 2.184878777433069e-05,
      "loss": 0.1209,
      "step": 9800
    },
    {
      "epoch": 1.7063081695966908,
      "grad_norm": 0.5295833945274353,
      "learning_rate": 2.1561530506721823e-05,
      "loss": 0.2262,
      "step": 9900
    },
    {
      "epoch": 1.723543605653223,
      "grad_norm": 0.03343662619590759,
      "learning_rate": 2.1274273239112952e-05,
      "loss": 0.1695,
      "step": 10000
    },
    {
      "epoch": 1.7407790417097553,
      "grad_norm": 9.384197235107422,
      "learning_rate": 2.0987015971504078e-05,
      "loss": 0.2254,
      "step": 10100
    },
    {
      "epoch": 1.7580144777662876,
      "grad_norm": 6.646634101867676,
      "learning_rate": 2.0699758703895207e-05,
      "loss": 0.2097,
      "step": 10200
    },
    {
      "epoch": 1.7752499138228197,
      "grad_norm": 0.1117960661649704,
      "learning_rate": 2.041250143628634e-05,
      "loss": 0.1786,
      "step": 10300
    },
    {
      "epoch": 1.7924853498793518,
      "grad_norm": 0.031827542930841446,
      "learning_rate": 2.012524416867747e-05,
      "loss": 0.1675,
      "step": 10400
    },
    {
      "epoch": 1.8097207859358841,
      "grad_norm": 0.2829335927963257,
      "learning_rate": 1.9837986901068598e-05,
      "loss": 0.1783,
      "step": 10500
    },
    {
      "epoch": 1.8269562219924165,
      "grad_norm": 0.06863640993833542,
      "learning_rate": 1.9550729633459727e-05,
      "loss": 0.1909,
      "step": 10600
    },
    {
      "epoch": 1.8441916580489486,
      "grad_norm": 0.09697156399488449,
      "learning_rate": 1.9263472365850856e-05,
      "loss": 0.2139,
      "step": 10700
    },
    {
      "epoch": 1.861427094105481,
      "grad_norm": 0.05059851333498955,
      "learning_rate": 1.8976215098241985e-05,
      "loss": 0.2648,
      "step": 10800
    },
    {
      "epoch": 1.8786625301620132,
      "grad_norm": 2.795382261276245,
      "learning_rate": 1.8688957830633118e-05,
      "loss": 0.2238,
      "step": 10900
    },
    {
      "epoch": 1.8958979662185453,
      "grad_norm": 0.019808555021882057,
      "learning_rate": 1.8401700563024247e-05,
      "loss": 0.1548,
      "step": 11000
    },
    {
      "epoch": 1.9131334022750774,
      "grad_norm": 14.030004501342773,
      "learning_rate": 1.8114443295415376e-05,
      "loss": 0.1663,
      "step": 11100
    },
    {
      "epoch": 1.9303688383316098,
      "grad_norm": 1.4134166240692139,
      "learning_rate": 1.7827186027806505e-05,
      "loss": 0.1844,
      "step": 11200
    },
    {
      "epoch": 1.947604274388142,
      "grad_norm": 12.42969036102295,
      "learning_rate": 1.753992876019763e-05,
      "loss": 0.1973,
      "step": 11300
    },
    {
      "epoch": 1.9648397104446742,
      "grad_norm": 0.028038611635565758,
      "learning_rate": 1.7252671492588764e-05,
      "loss": 0.1494,
      "step": 11400
    },
    {
      "epoch": 1.9820751465012065,
      "grad_norm": 0.8594577312469482,
      "learning_rate": 1.6965414224979893e-05,
      "loss": 0.2136,
      "step": 11500
    },
    {
      "epoch": 1.9993105825577389,
      "grad_norm": 0.020099906250834465,
      "learning_rate": 1.6678156957371022e-05,
      "loss": 0.1542,
      "step": 11600
    },
    {
      "epoch": 2.0,
      "eval_runtime": 40.3386,
      "eval_samples_per_second": 104.961,
      "eval_steps_per_second": 13.139,
      "step": 11604
    }
  ],
  "logging_steps": 100,
  "max_steps": 17406,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.82548160146944e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
